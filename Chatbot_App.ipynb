{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot from Scratch\n",
    "A Chatbot for mental health support\n",
    "\n",
    "Dataset source: https://www.kaggle.com/datasets/elvis23/mental-health-conversational-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"intents.json\", 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tag': 'greeting',\n",
       " 'patterns': ['Hi',\n",
       "  'Hey',\n",
       "  'Is anyone there?',\n",
       "  'Hi there',\n",
       "  'Hello',\n",
       "  'Hey there',\n",
       "  'Howdy',\n",
       "  'Hola',\n",
       "  'Bonjour',\n",
       "  'Konnichiwa',\n",
       "  'Guten tag',\n",
       "  'Ola'],\n",
       " 'responses': ['Hello there. Tell me how are you feeling today?',\n",
       "  'Hi there. What brings you here today?',\n",
       "  'Hi there. How are you feeling today?',\n",
       "  'Great to see you. How do you feel currently?',\n",
       "  \"Hello there. Glad to see you're back. What's going on in your world right now?\"]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['intents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_in_all_patterns: the vocabulary\n",
    "words_in_all_patterns = []\n",
    "all_tags = []\n",
    "tokenized_patterns_and_their_tags = []\n",
    "punctuations_to_remove = [',', '.', '?', '!', ';']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of all patterns tokenized and their tag\n",
    "# and a list of all unique tags in the data\n",
    "for dict in data['intents']:\n",
    "    for pattern in dict['patterns']:\n",
    "        tokenized_pattern = nltk.word_tokenize(pattern)\n",
    "        words_in_all_patterns.extend(tokenized_pattern)\n",
    "        tokenized_patterns_and_their_tags.append((tokenized_pattern, dict['tag']))\n",
    "        \n",
    "        if dict['tag'] not in all_tags:\n",
    "            all_tags.append(dict['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['I', \"'m\", 'so', 'anxious', 'because', 'of'], 'anxious'),\n",
       " (['I', 'do', \"n't\", 'want', 'to', 'talk', 'about', 'it', '.'], 'not-talking'),\n",
       " (['No', 'just', 'stay', 'away', '.'], 'not-talking'),\n",
       " (['I', 'ca', \"n't\", 'bring', 'myself', 'to', 'open', 'up', '.'],\n",
       "  'not-talking'),\n",
       " (['Just', 'shut', 'up'], 'not-talking')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_patterns_and_their_tags[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_patterns_and_their_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['greeting', 'morning', 'afternoon', 'evening', 'night', 'goodbye', 'thanks', 'no-response', 'neutral-response', 'about']\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "print(all_tags[:10])\n",
    "print(len(all_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'Hey', 'Is', 'anyone', 'there', '?', 'Hi', 'there', 'Hello', 'Hey']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_all_patterns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1203"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_in_all_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\durge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\durge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'hey', 'is', 'anyone', 'there', 'hi', 'there', 'hello', 'hey', 'there']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting words to lower case, lemmatization and punctuation removal\n",
    "words_in_all_patterns = [lemmatizer.lemmatize(word.lower()) \n",
    "                         for word in words_in_all_patterns \n",
    "                            if word not in punctuations_to_remove\n",
    "                        ]\n",
    "words_in_all_patterns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1086"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_in_all_patterns)  # Previous was 2406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " 'hey',\n",
       " 'is',\n",
       " 'anyone',\n",
       " 'there',\n",
       " 'hello',\n",
       " 'howdy',\n",
       " 'hola',\n",
       " 'bonjour',\n",
       " 'konnichiwa']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keeping only unique words\n",
    "unique_words_in_all_patterns = []\n",
    "for word in words_in_all_patterns:\n",
    "    if word not in unique_words_in_all_patterns:\n",
    "        unique_words_in_all_patterns.append(word)\n",
    "\n",
    "unique_words_in_all_patterns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words_in_all_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Patterns to Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['I', \"'m\", 'so', 'anxious', 'because', 'of'], 'anxious'),\n",
       " (['I', 'do', \"n't\", 'want', 'to', 'talk', 'about', 'it', '.'], 'not-talking'),\n",
       " (['No', 'just', 'stay', 'away', '.'], 'not-talking'),\n",
       " (['I', 'ca', \"n't\", 'bring', 'myself', 'to', 'open', 'up', '.'],\n",
       "  'not-talking'),\n",
       " (['Just', 'shut', 'up'], 'not-talking')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_patterns_and_their_tags[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it', 'depressed', 'think', \"'m\", 'depression']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words_in_all_patterns[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['greeting',\n",
       " 'morning',\n",
       " 'afternoon',\n",
       " 'evening',\n",
       " 'night',\n",
       " 'goodbye',\n",
       " 'thanks',\n",
       " 'no-response',\n",
       " 'neutral-response',\n",
       " 'about']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tags[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the training data\n",
    "# Preprocessing patterns - converting words to lower case, lemmatization and puncuation removal (same as words_in_all_patterns)\n",
    "\n",
    "training_data = []\n",
    "\n",
    "for tokenized_pattern_and_tag_pair in tokenized_patterns_and_their_tags:\n",
    "    bag_of_words_vec = [0] * len(unique_words_in_all_patterns)\n",
    "    one_hot_tag_vec = [0] * len(all_tags)\n",
    "\n",
    "    tokenized_pattern = tokenized_pattern_and_tag_pair[0]\n",
    "    tag_of_pattern = tokenized_pattern_and_tag_pair[1]\n",
    "    tokenized_pattern = [lemmatizer.lemmatize(word.lower()) \n",
    "                            for word in tokenized_pattern \n",
    "                                if word not in punctuations_to_remove\n",
    "                        ]\n",
    "\n",
    "    for word in tokenized_pattern:\n",
    "        if word in unique_words_in_all_patterns:\n",
    "            bag_of_words_vec[unique_words_in_all_patterns.index(word)] += 1\n",
    "    \n",
    "    \n",
    "    # for word in unique_words_in_all_patterns:\n",
    "    #     bag.append(1) if word in tokenized_pattern_and_tag_pair else bag.append(0)\n",
    "    \n",
    "    one_hot_tag_vec[all_tags.index(tag_of_pattern)] = 1\n",
    "    training_data.append([bag_of_words_vec, one_hot_tag_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(training_data[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Neural Network Model\n",
    "To generate tag for input pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape = (len(bag_of_words_vec), ), activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(all_tags), activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_optimizer = SGD(learning_rate = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = sgd_optimizer, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [vectorized_pattern_tag_pair[0] for vectorized_pattern_tag_pair in training_data]\n",
    "y_train = [vectorized_pattern_tag_pair[1] for vectorized_pattern_tag_pair in training_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "24/24 [==============================] - 1s 3ms/step - loss: 4.3845 - accuracy: 0.0210\n",
      "Epoch 2/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.3283 - accuracy: 0.0420\n",
      "Epoch 3/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.2868 - accuracy: 0.0588\n",
      "Epoch 4/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.2470 - accuracy: 0.0798\n",
      "Epoch 5/80\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 4.2051 - accuracy: 0.1050\n",
      "Epoch 6/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.1340 - accuracy: 0.0924\n",
      "Epoch 7/80\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.0513 - accuracy: 0.1092\n",
      "Epoch 8/80\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.0033 - accuracy: 0.0924\n",
      "Epoch 9/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.9410 - accuracy: 0.1008\n",
      "Epoch 10/80\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 3.8148 - accuracy: 0.1345\n",
      "Epoch 11/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.7840 - accuracy: 0.1176\n",
      "Epoch 12/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.6830 - accuracy: 0.1176\n",
      "Epoch 13/80\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 3.5589 - accuracy: 0.1387\n",
      "Epoch 14/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.4762 - accuracy: 0.1429\n",
      "Epoch 15/80\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 3.4316 - accuracy: 0.1765\n",
      "Epoch 16/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.2663 - accuracy: 0.1975\n",
      "Epoch 17/80\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.2313 - accuracy: 0.1891\n",
      "Epoch 18/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.1728 - accuracy: 0.2017\n",
      "Epoch 19/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.0271 - accuracy: 0.2353\n",
      "Epoch 20/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.0118 - accuracy: 0.2269\n",
      "Epoch 21/80\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2.9068 - accuracy: 0.2605\n",
      "Epoch 22/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.8338 - accuracy: 0.2269\n",
      "Epoch 23/80\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 2.7728 - accuracy: 0.2857\n",
      "Epoch 24/80\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 2.6716 - accuracy: 0.2857\n",
      "Epoch 25/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.5862 - accuracy: 0.3067\n",
      "Epoch 26/80\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 2.4089 - accuracy: 0.3782\n",
      "Epoch 27/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.5021 - accuracy: 0.3193\n",
      "Epoch 28/80\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.4713 - accuracy: 0.3319\n",
      "Epoch 29/80\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.3677 - accuracy: 0.3866\n",
      "Epoch 30/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.2611 - accuracy: 0.4244\n",
      "Epoch 31/80\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.2424 - accuracy: 0.4160\n",
      "Epoch 32/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.1480 - accuracy: 0.4160\n",
      "Epoch 33/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.1485 - accuracy: 0.4034\n",
      "Epoch 34/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.0404 - accuracy: 0.4328\n",
      "Epoch 35/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.9859 - accuracy: 0.4244\n",
      "Epoch 36/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.9297 - accuracy: 0.4580\n",
      "Epoch 37/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.9893 - accuracy: 0.4286\n",
      "Epoch 38/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.8656 - accuracy: 0.5000\n",
      "Epoch 39/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.8152 - accuracy: 0.4748\n",
      "Epoch 40/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.7184 - accuracy: 0.5504\n",
      "Epoch 41/80\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6347 - accuracy: 0.5462\n",
      "Epoch 42/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.6499 - accuracy: 0.5084\n",
      "Epoch 43/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.6189 - accuracy: 0.5504\n",
      "Epoch 44/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.6289 - accuracy: 0.5168\n",
      "Epoch 45/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.5998 - accuracy: 0.5336\n",
      "Epoch 46/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.5384 - accuracy: 0.5546\n",
      "Epoch 47/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.5959 - accuracy: 0.5630\n",
      "Epoch 48/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.4726 - accuracy: 0.5714\n",
      "Epoch 49/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.4487 - accuracy: 0.6092\n",
      "Epoch 50/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.3360 - accuracy: 0.6008\n",
      "Epoch 51/80\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.3269 - accuracy: 0.6218\n",
      "Epoch 52/80\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.3084 - accuracy: 0.6176\n",
      "Epoch 53/80\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.3849 - accuracy: 0.5966\n",
      "Epoch 54/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.3254 - accuracy: 0.6134\n",
      "Epoch 55/80\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.2215 - accuracy: 0.6933\n",
      "Epoch 56/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.2713 - accuracy: 0.6555\n",
      "Epoch 57/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.2897 - accuracy: 0.6218\n",
      "Epoch 58/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.2468 - accuracy: 0.6471\n",
      "Epoch 59/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.2294 - accuracy: 0.6723\n",
      "Epoch 60/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.0409 - accuracy: 0.7227\n",
      "Epoch 61/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.1375 - accuracy: 0.6555\n",
      "Epoch 62/80\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.1340 - accuracy: 0.6723\n",
      "Epoch 63/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.0941 - accuracy: 0.6891\n",
      "Epoch 64/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.0686 - accuracy: 0.7311\n",
      "Epoch 65/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.0447 - accuracy: 0.7017\n",
      "Epoch 66/80\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.9244 - accuracy: 0.7269\n",
      "Epoch 67/80\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.9939 - accuracy: 0.7227\n",
      "Epoch 68/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.9913 - accuracy: 0.6849\n",
      "Epoch 69/80\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.9280 - accuracy: 0.7269\n",
      "Epoch 70/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.8992 - accuracy: 0.7605\n",
      "Epoch 71/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.0249 - accuracy: 0.6891\n",
      "Epoch 72/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.8638 - accuracy: 0.7437\n",
      "Epoch 73/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.7954 - accuracy: 0.7689\n",
      "Epoch 74/80\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.8241 - accuracy: 0.7647\n",
      "Epoch 75/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.8593 - accuracy: 0.7647\n",
      "Epoch 76/80\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.8421 - accuracy: 0.7605\n",
      "Epoch 77/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.8995 - accuracy: 0.7605\n",
      "Epoch 78/80\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.8378 - accuracy: 0.7605\n",
      "Epoch 79/80\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.8419 - accuracy: 0.7563\n",
      "Epoch 80/80\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.8384 - accuracy: 0.7353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b67a445ca0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(X_train), np.array(y_train), epochs = 80, batch_size = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing user input in same way as words_in_all_patterns and tokenized_patterns\n",
    "def preprocess_user_input(user_input):\n",
    "    words_in_user_input = nltk.word_tokenize(user_input)\n",
    "    words_in_user_input = [ lemmatizer.lemmatize(word.lower()) \n",
    "                            for word in words_in_user_input \n",
    "                               if word not in punctuations_to_remove\n",
    "                            ]\n",
    "    return words_in_user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'very', 'stressed']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"I am very stressed.\"\n",
    "preprocess_user_input(user_input = prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " 'hey',\n",
       " 'is',\n",
       " 'anyone',\n",
       " 'there',\n",
       " 'hello',\n",
       " 'howdy',\n",
       " 'hola',\n",
       " 'bonjour',\n",
       " 'konnichiwa']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words_in_all_patterns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words_in_all_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bag_of_words(user_input):\n",
    "    words_in_cleaned_user_input = preprocess_user_input(user_input)\n",
    "    bag_of_words = [0] * len(unique_words_in_all_patterns)\n",
    "    \n",
    "    # w: word in user input\n",
    "    # word: word in the list of all words\n",
    "    for word in (words_in_cleaned_user_input):\n",
    "        if word in unique_words_in_all_patterns:\n",
    "            bag_of_words[unique_words_in_all_patterns.index(word)] += 1\n",
    "\n",
    "    # for w in words_in_cleaned_user_input:\n",
    "    #     for i, word in enumerate(words_in_all_patterns):\n",
    "    #         if word == w:\n",
    "    #             bag[i] = 1\n",
    "    \n",
    "    return np.array(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_prompt = make_bag_of_words(user_input = prompt)\n",
    "vectorized_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.81932511e-05, 1.66534679e-04, 5.06788747e-05, 2.76808623e-05,\n",
       "        6.19347324e-04, 4.75378192e-06, 9.43166378e-06, 1.89419996e-04,\n",
       "        2.72493577e-04, 9.25365930e-06, 8.61010540e-06, 2.68264248e-05,\n",
       "        4.91533428e-03, 2.16025164e-05, 5.10134362e-02, 9.00073230e-01,\n",
       "        2.34287675e-03, 5.89044951e-03, 1.48207238e-02, 8.40683235e-04,\n",
       "        4.88341693e-03, 8.11044883e-05, 5.10135083e-04, 2.47568882e-04,\n",
       "        4.85489145e-05, 2.89342938e-06, 5.46387600e-05, 9.54167219e-04,\n",
       "        1.44542457e-04, 6.46095759e-06, 1.02226331e-04, 1.56241615e-04,\n",
       "        7.26857763e-07, 7.69055532e-06, 5.76134084e-07, 2.59512558e-06,\n",
       "        1.62902623e-04, 4.05896601e-04, 2.12580402e-04, 4.63439705e-04,\n",
       "        1.03411812e-03, 7.59156886e-04, 1.19172955e-05, 8.67500421e-06,\n",
       "        1.62269163e-03, 9.45456617e-04, 1.53980695e-03, 1.18852258e-04,\n",
       "        7.26772560e-05, 7.42820976e-06, 2.42069636e-05, 8.41053625e-05,\n",
       "        1.21597748e-03, 1.31726638e-05, 1.81982497e-04, 7.88047691e-05,\n",
       "        8.80814987e-05, 8.31335128e-05, 5.11750877e-05, 2.25834679e-04,\n",
       "        4.74015796e-05, 3.19073624e-05, 3.50431837e-05, 2.80445747e-05,\n",
       "        6.47240404e-06, 6.86396888e-05, 7.48783787e-05, 1.73969151e-04,\n",
       "        2.57742620e-04, 1.63549732e-04, 1.29464688e-05, 7.53360073e-05,\n",
       "        2.19036519e-05, 2.21455557e-05, 5.15215906e-05, 4.42515739e-05,\n",
       "        9.48240049e-05, 6.17977057e-04, 2.73785718e-05, 1.76984351e-04]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output = model.predict(np.array([vectorized_prompt]), verbose = 0)\n",
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 80)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_output[0]), len(all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(model_output[0] == max(model_output[0]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stressed'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tags[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_for_user_input(user_input):\n",
    "    vectorized_user_input = make_bag_of_words(user_input)\n",
    "    model_output = model.predict(np.array([vectorized_user_input]), verbose = 0)\n",
    "\n",
    "    max_probability = max(model_output[0])\n",
    "    \n",
    "    if max_probability > 0.25:\n",
    "        predicted_tag = all_tags[np.where(model_output[0] == max_probability)[0][0]]\n",
    "        return predicted_tag\n",
    "    \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stressed\n"
     ]
    }
   ],
   "source": [
    "predicted_tag_for_prompt = get_tag_for_user_input(user_input = prompt)\n",
    "print(predicted_tag_for_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chatbot_response(predicted_tag):\n",
    "    if predicted_tag == None:\n",
    "        return \"Sorry. I do not understand.\"\n",
    "    else:\n",
    "        for dict in data['intents']:\n",
    "            if dict[\"tag\"] == predicted_tag:\n",
    "                return random.choice(dict[\"responses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Take a deep breath and gather your thoughts. Go take a walk if possible. Stay hydrated'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_chatbot_response(predicted_tag = predicted_tag_for_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is running!\n",
      "User: Good Morning\n",
      "Chatbot: Good morning. I hope you had a good night's sleep. How are you feeling today? \n",
      "\n",
      "User: I am feeling stressed\n",
      "Chatbot: I am sorry to hear that. What is the reason behind this?\n",
      "\n",
      "User: My exams are coming and I feel like I am not prepared\n",
      "Chatbot: I see. Have you taken any approaches to not feel this way?\n",
      "\n",
      "User: Yes. I try to do deep breathing to calm myself down but it doesn't seem to work. Can you help me?\n",
      "Chatbot: I understand how you feel. Don't put yourself down because of it.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22724\\1847671703.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Chatbot is running!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"User:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"User:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpredicted_tag_for_prompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_tag_for_user_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\durge\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1175\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             )\n\u001b[1;32m-> 1177\u001b[1;33m         return self._input_request(\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\durge\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1217\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1219\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1220\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "print(\"Chatbot is running!\")\n",
    "while True:\n",
    "    prompt = input(\"User:\")\n",
    "    print(\"User:\", prompt)\n",
    "    predicted_tag_for_prompt = get_tag_for_user_input(prompt)\n",
    "    response = get_chatbot_response(predicted_tag = predicted_tag_for_prompt)\n",
    "    print(\"Chatbot:\", response)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
